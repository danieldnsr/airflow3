# DAGs de Prueba - Hola Mundo con Docker y Kubernetes

Este proyecto contiene dos DAGs de Apache Airflow para probar la integraci√≥n con Docker y Kubernetes.

## üìÅ Estructura del Proyecto

```
airflow3/
‚îú‚îÄ‚îÄ dags/
‚îÇ   ‚îú‚îÄ‚îÄ hello_world_docker_dag.py    # DAG con DockerOperator
‚îÇ   ‚îî‚îÄ‚îÄ hello_world_k8s_dag.py       # DAG con KubernetesPodOperator
‚îú‚îÄ‚îÄ docs/
‚îú‚îÄ‚îÄ values-minimal.yaml              # Configuraci√≥n de Airflow para Kubernetes
‚îî‚îÄ‚îÄ postgres-deployment.yaml        # Deployment de PostgreSQL
```

## üöÄ DAGs Incluidos

### 1. `hello_world_docker` (DockerOperator)

**Archivo:** `dags/hello_world_docker_dag.py`

Este DAG ejecuta contenedores Docker directamente y contiene 3 tareas:

1. **docker_hola_mundo**: Saludo b√°sico con Alpine Linux
2. **docker_system_info**: Informaci√≥n del sistema 
3. **docker_python_hello**: Prueba con Python

**Caracter√≠sticas:**
- Usa im√°genes ligeras (`alpine:latest`, `python:3.9-alpine`)
- Auto-eliminaci√≥n de contenedores (`auto_remove=True`)
- Ejecuci√≥n manual (`schedule_interval=None`)

### 2. `hello_world_kubernetes` (KubernetesPodOperator)

**Archivo:** `dags/hello_world_k8s_dag.py`

Este DAG ejecuta pods de Kubernetes y contiene 4 tareas:

1. **k8s_hola_mundo**: Saludo b√°sico en pod Alpine
2. **k8s_cluster_info**: Informaci√≥n del cluster de Kubernetes
3. **k8s_ubuntu_tools**: Prueba con Ubuntu y herramientas
4. **k8s_python_advanced**: Script avanzado de Python

**Caracter√≠sticas:**
- Configuraci√≥n de recursos CPU/memoria
- Auto-eliminaci√≥n de pods despu√©s de la ejecuci√≥n
- Logs detallados de cada pod
- Namespace configurable (por defecto: `default`)

## üõ†Ô∏è Configuraci√≥n y Despliegue

### Requisitos Previos

1. **Minikube** ejecut√°ndose
2. **Airflow** desplegado en Kubernetes usando Helm
3. **Docker** disponible en los nodos de Kubernetes
4. **PostgreSQL** ejecut√°ndose (usando `postgres-deployment.yaml`)

### Pasos para Desplegar

1. **Verificar que Airflow est√© ejecut√°ndose:**
   ```bash
   kubectl get pods -l app.kubernetes.io/name=airflow
   ```

2. **Copiar los DAGs al volumen persistente de Airflow:**
   
   Si usas vol√∫menes persistentes, copia la carpeta `dags/` al volumen correspondiente.
   
   Si usas GitSync (recomendado), haz commit y push de los DAGs:
   ```bash
   git add dags/
   git commit -m "Agregar DAGs de prueba Hola Mundo"
   git push origin main
   ```

3. **Verificar que los DAGs aparezcan en la UI de Airflow:**
   - Accede a la UI de Airflow
   - Ve a la pesta√±a "DAGs"
   - Deber√≠as ver `hello_world_docker` y `hello_world_kubernetes`

### Acceder a la UI de Airflow

Si configuraste el servicio como `NodePort`:

```bash
# Obtener la URL del servicio
minikube service airflow-webserver --url

# O hacer port-forwarding
kubectl port-forward svc/airflow-webserver 8080:8080
# Luego acceder a http://localhost:8080
```

**Credenciales por defecto:**
- Usuario: `admin`
- Contrase√±a: `admin`

## üß™ C√≥mo Probar los DAGs

### 1. Probar el DAG de Docker

1. En la UI de Airflow, busca `hello_world_docker`
2. Activa el DAG (toggle ON)
3. Haz clic en "Trigger DAG" para ejecutarlo manualmente
4. Ve a "Graph View" para monitorear el progreso
5. Haz clic en cada tarea para ver los logs

### 2. Probar el DAG de Kubernetes

1. En la UI de Airflow, busca `hello_world_kubernetes`
2. Activa el DAG (toggle ON)
3. Haz clic en "Trigger DAG"
4. Monitorea en "Graph View"
5. Los pods se ejecutar√°n en paralelo/secuencia seg√∫n las dependencias

### 3. Verificar desde la Terminal

```bash
# Ver pods de Airflow
kubectl get pods -l app.kubernetes.io/name=airflow

# Ver logs de un pod espec√≠fico (mientras se ejecuta)
kubectl logs <pod-name> -f

# Ver todos los pods (incluyendo los temporales de las tareas)
kubectl get pods --all-namespaces
```

## üîß Troubleshooting

### Error: "Docker not found"
- Verifica que Docker est√© instalado en los nodos de Kubernetes
- Aseg√∫rate de que el socket de Docker (`/var/run/docker.sock`) est√© montado

### Error: "Image pull failed"
- Verifica conectividad a internet desde el cluster
- Las im√°genes (`alpine`, `python`, `ubuntu`) se descargan autom√°ticamente

### Error: "Pod creation timeout"
- Aumenta `startup_timeout_seconds` en el KubernetesPodOperator
- Verifica recursos disponibles: `kubectl describe nodes`

### Los DAGs no aparecen en la UI
- Verifica que los archivos est√©n en la ruta correcta de DAGs
- Revisa logs del scheduler: `kubectl logs deployment/airflow-scheduler`
- Verifica sintaxis de Python: `python -m py_compile dags/hello_world_*.py`

## üìä Logs y Monitoreo

### Ver logs de tareas Docker:
- En la UI de Airflow: Task Instance ‚Üí View Log
- Los logs mostrar√°n la salida de los comandos Docker

### Ver logs de tareas Kubernetes:
- En la UI de Airflow: Task Instance ‚Üí View Log  
- Tambi√©n puedes usar: `kubectl logs <pod-name>` mientras el pod existe

### Monitorear recursos:
```bash
# CPU y memoria de los pods
kubectl top pods

# Eventos del cluster
kubectl get events --sort-by=.metadata.createdAt

# Estado de los nodos
kubectl get nodes
kubectl describe nodes
```

## üéØ Pr√≥ximos Pasos

Una vez que estos DAGs funcionen correctamente, puedes:

1. **Agregar m√°s complejidad:** Tareas con dependencias de datos
2. **Integrar con almacenamiento:** Usar PersistentVolumes
3. **Agregar monitoring:** Prometheus + Grafana
4. **Configurar alertas:** Slack, email, etc.
5. **Usar secretos:** Para credenciales sensibles
6. **Implementar CI/CD:** Para despliegue automatizado de DAGs

## üìù Notas Adicionales

- Los DAGs est√°n configurados para ejecuci√≥n manual (`schedule_interval=None`)
- Los recursos est√°n limitados para funcionar en Minikube
- Los pods se eliminan autom√°ticamente despu√©s de la ejecuci√≥n
- Los contenedores Docker tambi√©n se auto-eliminan

¬°Disfruta probando tu setup de Airflow + Kubernetes! üéâ